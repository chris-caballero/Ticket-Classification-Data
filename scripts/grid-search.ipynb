{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from utils.utils import *\n",
    "from utils.data import TicketDataset, to_dataloader\n",
    "from utils.models import ConvNet, EncoderTransformer\n",
    "from utils.model_utils import get_class_weights\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "support_tickets_file = '../data/preprocessed_labeled_complaints.pkl'\n",
    "save_models = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the Preprocessed Data\n",
    "***\n",
    "* For simplicity, I preprocessed the data using my own implementations of the methods used by the author of the dataset and saved the results into an new file so that the data is ready to use.\n",
    "* This dataset is pulled from Kaggle, where users upload **open-source** datasets for almost any topic.\n",
    "* The author of the Automatic Ticket Classification Dataset: https://www.kaggle.com/venkatasubramanian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint</th>\n",
       "      <th>complaint_lemma</th>\n",
       "      <th>complaint_nouns</th>\n",
       "      <th>topic</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26063</th>\n",
       "      <td>i booked a rental car to be picked up in   and...</td>\n",
       "      <td>I book a rental car to be pick up in    and re...</td>\n",
       "      <td>book car pay ink business credit fee advance f...</td>\n",
       "      <td>Theft / Dispute reporting</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21143</th>\n",
       "      <td>and   submit these letters of negotiation on s...</td>\n",
       "      <td>and    submit these letter of negotiation on s...</td>\n",
       "      <td>letter negotiation credit card consumer protec...</td>\n",
       "      <td>Credit card / Prepaid card</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3745</th>\n",
       "      <td>my account was closed for no reason i am a vic...</td>\n",
       "      <td>my account be close for no reason I be a victi...</td>\n",
       "      <td>account reason victim bank discrimination prac...</td>\n",
       "      <td>Bank account services</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22953</th>\n",
       "      <td>i was on a lunch break and went through a driv...</td>\n",
       "      <td>I be on a lunch break and go through a drive t...</td>\n",
       "      <td>lunch break drive thru card online banking acc...</td>\n",
       "      <td>Credit card / Prepaid card</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40413</th>\n",
       "      <td>the ssi deposited money by error in my chase b...</td>\n",
       "      <td>the ssi deposit money by error in my chase ban...</td>\n",
       "      <td>deposit money error bank account money pende b...</td>\n",
       "      <td>Bank account services</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               complaint  \\\n",
       "26063  i booked a rental car to be picked up in   and...   \n",
       "21143  and   submit these letters of negotiation on s...   \n",
       "3745   my account was closed for no reason i am a vic...   \n",
       "22953  i was on a lunch break and went through a driv...   \n",
       "40413  the ssi deposited money by error in my chase b...   \n",
       "\n",
       "                                         complaint_lemma  \\\n",
       "26063  I book a rental car to be pick up in    and re...   \n",
       "21143  and    submit these letter of negotiation on s...   \n",
       "3745   my account be close for no reason I be a victi...   \n",
       "22953  I be on a lunch break and go through a drive t...   \n",
       "40413  the ssi deposit money by error in my chase ban...   \n",
       "\n",
       "                                         complaint_nouns  \\\n",
       "26063  book car pay ink business credit fee advance f...   \n",
       "21143  letter negotiation credit card consumer protec...   \n",
       "3745   account reason victim bank discrimination prac...   \n",
       "22953  lunch break drive thru card online banking acc...   \n",
       "40413  deposit money error bank account money pende b...   \n",
       "\n",
       "                            topic  label  \n",
       "26063   Theft / Dispute reporting      3  \n",
       "21143  Credit card / Prepaid card      1  \n",
       "3745        Bank account services      0  \n",
       "22953  Credit card / Prepaid card      1  \n",
       "40413       Bank account services      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickets = pd.read_pickle(support_tickets_file)\n",
    "tickets.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "dataset = TicketDataset(tickets, tokenizer)\n",
    "trainset, testset = to_dataloader(dataset, batch_size=16, split=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['on   i made a  payment to an online retailer using chase quick pay with  on the chase website i realized that this was a scam website after no confirmation product or response to any inquiries regarding the order and contacted chase to get more information about the transaction to attempt getting a refund through the retailers bank \\n\\ni contacted chase via a secured message on  explaining what happened and asked  is there a way to reverse this transaction or do you have a contact at  that can give me more information about the recipient  that  my message was reviewed and i received a response restating my original email and informing me that  the transfer has been completed however as you mentioned that the website is a scam while we can handle most inquiries by email some require the expertise of another team in order to assist you better in regards to the refund we request you to call our consumer online technical support team  i called the number listed in the email and explained my situation to then be transferred to the claims department i was directed to call  and ask them about the transaction because chase did not have any information outside of what i provided when initiating the transfer i felt like this agent was trying to get me to end the call as quickly as possible and i had to interrupt her closing script to ask for a contact number at  and didnt have an opportunity to get any information about what the right questions would be to ask  or what words and phrases i should use to get the information i was looking for \\n\\ni called  whos automated system initially directed me to call my bank because i used the banks app to initiate the transaction i called  again to navigate their menus and talk to a customer service agent they told me that all of the information about the transaction would in chase s system because i used the banks app to perform the transaction she stayed on the line with me until i understood everything that i should ask and had a better understanding of the situation i ended the call and called chase again \\n\\nwhen i called chase the second time the agent tried to look up the information about the receiving bank but could not find any additional information she then asked me why i needed this information and i explained my situation again i was once again transferred to the claims department who told me that i needed to contact  to get the information i was looking for after i told her that i had already contacted them she finally admitted that there was nothing that she could do due to the nature of the transaction and that these types of transactions are not secured she said that chase had no information about the recipient other than the email address that i inputted and that the recipients banking information was not kept in the system in both phone calls they asked if i initiated that transaction and used that to absolve themselves of all responsibility in regards to this matter \\n\\nduring this whole process it felt like chase was not transparent about their policies regarding these types of transactions nor were they helpful in helping me get any information about the situation these transactions are advertised as a  fast safe and easy way to send money  but seem to be a dangerous way to do business i feel deceived by chase s advertising and further victimized by the way i was treated by the members on their customer service team',\n",
       "       'to whom it may concern chase bank charged wrongly overdraft fees i have alert of low balance or unsuficent fee balance and always deposit immediatly to cover transactions if needed but chase always changed the order and charged me overdraft fee anyway when you call they said their per their guidelines they dont refund more then  overdrawft doesnt matter bank fault or not\\n\\ntaken  from people is money just because you can is not ok\\n\\nsee attached documents when chase refund they always find the way to take back what they refunded in first place',\n",
       "       'my chase amazon card was declined for a catering order i had placed for my brothers funeral in the amount of  i contacted chase around noon today  and was asked the last  numbers of my chase savings account and the other user on my account i responded that i did not have a savings and i am only authorized user customer rep told me they would call me back in  minutes to keep the line open i didnt receive a call back after an hour so i contacted chase from the first call i thought someone was using my card fraudulently i spoke to the rep who transferred me to a supervisor  who said the card was activated and the transaction would process called the catering company and card was declined i then used my    card to pay for the order   texted me asking if i was authorizing purchase and i responded yes contacted caterer and    was declined i contacted chase again spoke to rep was told the initial questions are used to trick people to see what there answer would be she told me the cvv code was incorrectly being input by the caterer and i responded that i had gone over the numbers and cvv used was correct she told me the card was cleared for the purchase and she would monitor it for  hours called caterer  card declined use a mastercard  which processed went to use chase amazon at restaurant at  pm tonight in the amount of   it was declined i was told by chase i was not over limit still frustrated figuring out multiple declines after several conversations with chase stating the card would be ok to use embarrassed as the caterer kept suggesting i was over my limit which i pay my card in full every month and chase confirmed that i was under my limit with the  transaction never been declined by either chase or    before  today after multiple assurances that i was all set and card would be monitored to make sure transaction would clear  it never did',\n",
       "       ...,\n",
       "       'on  i filed a dispute with my credit card company  chase visa  for an online purchase made on  chase visa kept closing the dispute even though it wasnt resolved acting upon misinformation from the vendor when i called to discuss and provide necessary documentation they advised me to  reopen  another dispute i did so four    times since my written disputes werent getting reviewed i attempted a phone resolution many times with many chase associates  most of which had foreign accents  i became very frustrated with their service and visited my local chase branch to seek assistance the branch manager  escalated  the matter only to then discover it was past the time it could be disputed  due to chase visa failing to research discuss and act upon the original dispute dated  as well as the many followup  reopened  disputes this was no fault of my own and chase must take responsibility for their failure to resolve this matter',\n",
       "       'on wednesday  i called chas my   visa credit card provider and asked how to make a claim under their purchase protection benefit on  i purchased three high school textbooks for my  year old daughter because she transferred to a new school all three books were damaged when a water bottle in her backpack broke the chase representative assured me the textbooks would be covered and instructed me to file a claim at  i immediately went to the website and filed the claim including uploading all of the requested paperwork which included a copy of my credit card statement copies of the three receipts and photographic evidence of the damage the website even had  books  as one of the catagories i could list as the type of item they cover and that i could make a claim on after following up repeatedly on my claim since the insurance provider failed to  review my information and contact me within  business days to outline the next steps of the process  as outlined in an email i received acknowledging my claim submission i called to complain the representative said claims are not looked at by an examiner  for eight to ten days  and then it would take  two days to actually review the claim  i responded that this information was contradictory to the information provided in writing in the email  sent to me and she said that she is not an adjuster and that is how it works i then asked to speak with an adjuster and she agreed to connect me to one i was then put on hold and when she returned she said my file had  just been updated while i was on hold and that the claim was being denied because textbooks have finite lives and are undergo revision after courses end  i explained that my daughter s course had not ended and that i was told specifically by chase that my textbook purchases would be covered and was again told they were refusing my claim  by the time the call ended i received an email stating that my claim status had been updated and was being denied i find this completely outrageous and borderline fraudulent',\n",
       "       'i am not familiar with  pay and did not understand the great risk this provides to consumers i believed this to be safe as it was through my chase bank app i have been with chase for almost  years and trust their mobile banking and now am sadly regretful i am being told to deal with the merchant except the merchant has refused to answer my inquiries and now shut down communication the website of the said merchant looks entirely legitamite and is even using the faces of highly successful brands with individuals linked to their social media without their consent in performing research of the phone number and other associated information available through pi it is very clear this merchant is continually creating new account title holders to perpetuate this cycle of fraud furthermore as this is a non fixed voip being used i believe they are fraudulently using the identity of the real   chase bank told me they wouldnt even investigate report this to  or allow me to file a report or take any potential recourse for the matter there isnt even a protocol in place to address this issue yet the chase mobile app verbiage makes a point to deceptively position this app as under the branch of chase banking service and as such imply a degree of entitlement to its customer service protection protocols chase has your back which reads on the very same link as the  tab  is most certainly not true this places consumers at risk when using this mobile service and does not flag the concern of chase in the slightest at minimum the risk of using  on your mobile banking app must realistically be made aware to the public as it stands to be potentially devastating i have plans to file reports with all corresponding authorities as well as notify and contact the individual whose identity is being misused to inform him i also intend to urge my neighbor who works in television that the news network should perhaps present the risk of using  and  integrated banking apps to the public i understand fraud and scamming are overwhelming rampant but a banking mogul such as chase not having any recourse of action is simply a risk that needs to be disclosed more throughly i would not have clicked on the to link to the extent i did if i would have been better informed'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickets[tickets.topic == 'Theft / Dispute reporting'].complaint.values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing Models & Hyper-Parameters\n",
    "***\n",
    "* **EncoderTransformer** is my implementation of a transformer ticket classifier.\n",
    "* **ConvNet** is my approximation of the neural network described in the paper: *Hyperparameter Black-Box Optimization to Improve the Automatic Classification of Support Tickets*, which I am trying to improve upon with my EncoderTranformer."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "block_size = 200\n",
    "num_filters = 512\n",
    "embedding_dim = 300\n",
    "num_ticket_classes = 5\n",
    "filter_sizes = [5, 4, 3]\n",
    "vocabulary_size = len(dataset.tokenizer.vocab)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "class_weights = get_class_weights(torch.tensor(tickets['label'].tolist()), num_ticket_classes, mode=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer = EncoderTransformer(\n",
    "#     vocabulary_size, embedding_dim, block_size, num_ticket_classes\n",
    "# ).to(device)\n",
    "# cnn = ConvNet(\n",
    "#     vocabulary_size, embedding_dim, num_filters, filter_sizes, num_ticket_classes\n",
    "# ).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train & Evaluate the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "# Custom PyTorch estimator for scikit-learn\n",
    "class PyTorchEstimator:\n",
    "    def __init__(self, vocab_size=None, lr=1e-2, embedding_dim=300, activation_conv='relu', activation_dense='softmax', mode=2, num_filters=512, filter_sizes=[3,4,5], optimizer_func='adam', batch_size=16, num_epochs=5, num_classes=5, device=torch.device('cpu')):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.lr = lr\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.activation_conv = activation_conv\n",
    "        self.activation_dense = activation_dense\n",
    "        self.optimizer_func = optimizer_func\n",
    "        self.num_filters = num_filters\n",
    "        self.filter_sizes = filter_sizes\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.device = device\n",
    "        self.mode = mode\n",
    "        self.num_classes = num_classes\n",
    "    \n",
    "    def set_vocab_size(self, vocab_size):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.model, self.optimizer = self.build_cnn()\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        # Return a dictionary of the estimator's parameters\n",
    "        return {\n",
    "            'vocab_size': self.vocab_size,\n",
    "            'lr': self.lr,\n",
    "            'embedding_dim': self.embedding_dim,\n",
    "            'activation_conv': self.activation_conv,\n",
    "            'activation_dense': self.activation_dense,\n",
    "            'mode': self.mode,\n",
    "            'num_filters': self.num_filters,\n",
    "            'filter_sizes': self.filter_sizes,\n",
    "            'optimizer_func': self.optimizer_func,\n",
    "            'batch_size': self.batch_size,\n",
    "            'num_epochs': self.num_epochs,\n",
    "            'num_classes': self.num_classes,\n",
    "            'device': self.device\n",
    "        }\n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        # Update the estimator's parameters with the given values\n",
    "        for key, value in params.items():\n",
    "            setattr(self, key, value)\n",
    "        # Rebuild the model, optimizer, and class weights based on the new parameters\n",
    "        self.model, self.optimizer = self.build_cnn()\n",
    "        return self\n",
    "    \n",
    "    def build_cnn(self):\n",
    "        if self.vocab_size is None:\n",
    "            raise ValueError(\"Vocabulary size is None.\")\n",
    "        \n",
    "        activation_map = {\n",
    "            \"relu\": nn.ReLU,\n",
    "            \"tanh\": nn.Tanh,\n",
    "            \"sigmoid\": nn.Sigmoid,\n",
    "            \"elu\": nn.ELU,\n",
    "            \"softsign\": nn.Softsign,\n",
    "            \"softmax\": nn.Softmax\n",
    "        }\n",
    "        optimizer_map = {\n",
    "            \"adam\": torch.optim.Adam, \n",
    "            \"adamax\": torch.optim.Adamax, \n",
    "            \"rmsprop\": torch.optim.RMSprop, \n",
    "            \"sgd\": torch.optim.SGD\n",
    "        }\n",
    "        conv_activation_layer = activation_map[self.activation_conv]()\n",
    "        dense_activation_layer = activation_map[self.activation_dense]()\n",
    "        model = ConvNet(\n",
    "            self.vocab_size, \n",
    "            self.embedding_dim, \n",
    "            self.num_filters, \n",
    "            self.filter_sizes, \n",
    "            self.num_classes,\n",
    "            conv_activation_layer=conv_activation_layer, \n",
    "            dense_activation_layer=dense_activation_layer\n",
    "        ).to(self.device)\n",
    "        optimizer = optimizer_map[self.optimizer_func](model.parameters(), lr=self.lr)\n",
    "\n",
    "        return model, optimizer\n",
    "    \n",
    "    def compute_class_weights(self, data):\n",
    "        return get_class_weights(\n",
    "            torch.tensor(data['label'].tolist()), \n",
    "            self.num_classes, \n",
    "            mode=self.mode\n",
    "        ).to(self.device)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Convert X and y to PyTorch tensors\n",
    "        X_tensor = torch.tensor(X, dtype=torch.long, device=self.device)\n",
    "        y_tensor = torch.tensor(y, dtype=torch.long, device=self.device)\n",
    "        optimizer = self.optimizer\n",
    "        class_weights = None\n",
    "\n",
    "        if class_weights is None:\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        else:\n",
    "            criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            for input_ids, targets in zip(X_tensor, y_tensor):\n",
    "                # input_ids = batch['input_ids'].to(self.device)\n",
    "                # targets = batch['labels'].to(self.device)\n",
    "\n",
    "                outputs = self.model(input_ids)\n",
    "                labels = nn.functional.one_hot(targets, num_classes=5).type(torch.float32).to(device)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "            if epoch % 10 == 0:\n",
    "                print(f'Epoch: {epoch} - Loss: {loss}')\n",
    "\n",
    "    def predict(self, testloader):\n",
    "        self.model.eval()\n",
    "        predictions = []\n",
    "        with torch.no_grad():\n",
    "            for inputs in testloader:\n",
    "                inputs = inputs.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                predictions.extend(preds.cpu().numpy())\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def score(self, testloader):\n",
    "        y_true = []\n",
    "        y_pred = self.predict(testloader)\n",
    "        for _, targets in testloader:\n",
    "            y_true.extend(targets.numpy())\n",
    "        return accuracy_score(y_true, y_pred)\n",
    "\n",
    "def custom_scorer(estimator, X, y=None):\n",
    "    return estimator.score(X) if y is None else estimator.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader_to_numpy(train_loader):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        X.append(batch['input_ids'].numpy())\n",
    "        y.append(batch['labels'].numpy())\n",
    "    \n",
    "    X = np.concatenate(X)\n",
    "    y = np.concatenate(y)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\chris\\Desktop\\Algo Project\\scripts\\project-grid.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chris/Desktop/Algo%20Project/scripts/project-grid.ipynb#X25sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m X, y \u001b[39m=\u001b[39m dataloader_to_numpy(trainset)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chris/Desktop/Algo%20Project/scripts/project-grid.ipynb#X25sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m halving_grid_search \u001b[39m=\u001b[39m HalvingGridSearchCV(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chris/Desktop/Algo%20Project/scripts/project-grid.ipynb#X25sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     estimator, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chris/Desktop/Algo%20Project/scripts/project-grid.ipynb#X25sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     hyperparameters, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chris/Desktop/Algo%20Project/scripts/project-grid.ipynb#X25sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     aggressive_elimination\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chris/Desktop/Algo%20Project/scripts/project-grid.ipynb#X25sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/chris/Desktop/Algo%20Project/scripts/project-grid.ipynb#X25sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m halving_grid_search\u001b[39m.\u001b[39;49mfit(X, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chris/Desktop/Algo%20Project/scripts/project-grid.ipynb#X25sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# Best hyperparameters\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chris/Desktop/Algo%20Project/scripts/project-grid.ipynb#X25sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m best_params \u001b[39m=\u001b[39m halving_grid_search\u001b[39m.\u001b[39mbest_params_\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search_successive_halving.py:273\u001b[0m, in \u001b[0;36mBaseSuccessiveHalving.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_input_parameters(\n\u001b[0;32m    266\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m    267\u001b[0m     y\u001b[39m=\u001b[39my,\n\u001b[0;32m    268\u001b[0m     groups\u001b[39m=\u001b[39mgroups,\n\u001b[0;32m    269\u001b[0m )\n\u001b[0;32m    271\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_samples_orig \u001b[39m=\u001b[39m _num_samples(X)\n\u001b[1;32m--> 273\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mfit(X, y\u001b[39m=\u001b[39my, groups\u001b[39m=\u001b[39mgroups, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    275\u001b[0m \u001b[39m# Set best_score_: BaseSearchCV does not set it, as refit is a callable\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_score_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv_results_[\u001b[39m\"\u001b[39m\u001b[39mmean_test_score\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_index_]\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search_successive_halving.py:378\u001b[0m, in \u001b[0;36mBaseSuccessiveHalving._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m    371\u001b[0m     cv \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checked_cv_orig\n\u001b[0;32m    373\u001b[0m more_results \u001b[39m=\u001b[39m {\n\u001b[0;32m    374\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39miter\u001b[39m\u001b[39m\"\u001b[39m: [itr] \u001b[39m*\u001b[39m n_candidates,\n\u001b[0;32m    375\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mn_resources\u001b[39m\u001b[39m\"\u001b[39m: [n_resources] \u001b[39m*\u001b[39m n_candidates,\n\u001b[0;32m    376\u001b[0m }\n\u001b[1;32m--> 378\u001b[0m results \u001b[39m=\u001b[39m evaluate_candidates(\n\u001b[0;32m    379\u001b[0m     candidate_params, cv, more_results\u001b[39m=\u001b[39;49mmore_results\n\u001b[0;32m    380\u001b[0m )\n\u001b[0;32m    382\u001b[0m n_candidates_to_keep \u001b[39m=\u001b[39m ceil(n_candidates \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfactor)\n\u001b[0;32m    383\u001b[0m candidate_params \u001b[39m=\u001b[39m _top_k(results, n_candidates_to_keep, itr)\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "\u001b[1;32mc:\\Users\\chris\\Desktop\\Algo Project\\scripts\\project-grid.ipynb Cell 14\u001b[0m in \u001b[0;36mPyTorchEstimator.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/chris/Desktop/Algo%20Project/scripts/project-grid.ipynb#X25sZmlsZQ%3D%3D?line=104'>105</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_epochs):\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/chris/Desktop/Algo%20Project/scripts/project-grid.ipynb#X25sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m     \u001b[39mfor\u001b[39;00m input_ids, targets \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(X_tensor, y_tensor):\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/chris/Desktop/Algo%20Project/scripts/project-grid.ipynb#X25sZmlsZQ%3D%3D?line=106'>107</a>\u001b[0m         \u001b[39m# input_ids = batch['input_ids'].to(self.device)\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/chris/Desktop/Algo%20Project/scripts/project-grid.ipynb#X25sZmlsZQ%3D%3D?line=107'>108</a>\u001b[0m         \u001b[39m# targets = batch['labels'].to(self.device)\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/chris/Desktop/Algo%20Project/scripts/project-grid.ipynb#X25sZmlsZQ%3D%3D?line=109'>110</a>\u001b[0m         outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(input_ids)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/chris/Desktop/Algo%20Project/scripts/project-grid.ipynb#X25sZmlsZQ%3D%3D?line=110'>111</a>\u001b[0m         labels \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mone_hot(targets, num_classes\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mfloat32)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/chris/Desktop/Algo%20Project/scripts/project-grid.ipynb#X25sZmlsZQ%3D%3D?line=112'>113</a>\u001b[0m         loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\chris\\Desktop\\Algo Project\\scripts\\utils\\models.py:39\u001b[0m, in \u001b[0;36mConvNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 39\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding(x)\n\u001b[0;32m     40\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n\u001b[0;32m     41\u001b[0m     x \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_activation_layer(conv(x))\u001b[39m.\u001b[39msqueeze(\u001b[39m3\u001b[39m) \u001b[39mfor\u001b[39;00m conv \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs]\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:158\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 158\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[0;32m    159\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[0;32m    160\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[1;32mc:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2183\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2177\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2178\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2179\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2180\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2181\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2182\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2183\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    \"lr\": [1e-1, 1e-2, 1e-3],\n",
    "    \"embedding_dim\": [200, 300, 400, 500],\n",
    "    \"activation_conv\": [\"relu\", \"elu\", \"tanh\", \"sigmoid\", \"softsign\"],\n",
    "    \"activation_dense\": [\"relu\", \"softmax\", \"sigmoid\"],\n",
    "    \"optimizer_func\": [\"adam\", \"adamax\", \"rmsprop\", \"sgd\"],\n",
    "    \"filter_sizes\": [[3,4,5], [5,4,3], [3,5,7], [7,5,3]],\n",
    "    \"mode\": [1, 2, 3]\n",
    "}\n",
    "\n",
    "# Perform the halving grid search\n",
    "estimator = PyTorchEstimator(device=device)\n",
    "estimator.set_vocab_size(vocabulary_size)\n",
    "\n",
    "X, y = dataloader_to_numpy(trainset)\n",
    "\n",
    "halving_grid_search = HalvingGridSearchCV(\n",
    "    estimator, \n",
    "    hyperparameters, \n",
    "    scoring=custom_scorer, \n",
    "    resource='num_epochs', \n",
    "    max_resources=5,\n",
    "    aggressive_elimination=True\n",
    ")\n",
    "halving_grid_search.fit(X, y)\n",
    "\n",
    "# Best hyperparameters\n",
    "best_params = halving_grid_search.best_params_\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "# Evaluate on test set\n",
    "best_estimator = halving_grid_search.best_estimator_\n",
    "test_accuracy = best_estimator.score(testset)\n",
    "print(\"Test accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Models\n",
    "***\n",
    "If you wish to save the trained models, please uncomment the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
